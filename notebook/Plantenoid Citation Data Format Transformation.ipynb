{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data from Raw Citation (Cora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data version\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg.eigen.arpack import eigsh\n",
    "import sys\n",
    "\n",
    "path=\"../data/ori_cora_data/cora/\" \n",
    "dataset=\"cora\"\n",
    "idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset),dtype=np.dtype(str))\n",
    "features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
    "# features = normalize(features) # no normalization in plantoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = encode_onehot(idx_features_labels[:, -1])\n",
    "# build graph\n",
    "idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
    "idx_map = {j: i for i, j in enumerate(idx)}\n",
    "edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset),\n",
    "                                dtype=np.int32)\n",
    "edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
    "                 dtype=np.int32).reshape(edges_unordered.shape)\n",
    "adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
    "                    shape=(labels.shape[0], labels.shape[0]),\n",
    "                    dtype=np.float32)\n",
    "\n",
    "# build symmetric adjacency matrix\n",
    "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "idx_train = range(140)\n",
    "idx_val = range(200, 500)\n",
    "idx_test = range(500, 1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as Planetoid Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loads input data from gcn/data directory\n",
    "\n",
    "ind.dataset_str.x => the feature vectors of the training instances as scipy.sparse.csr.csr_matrix object;\n",
    "ind.dataset_str.tx => the feature vectors of the test instances as scipy.sparse.csr.csr_matrix object;\n",
    "ind.dataset_str.allx => the feature vectors of both labeled and unlabeled training instances\n",
    "    (a superset of ind.dataset_str.x) as scipy.sparse.csr.csr_matrix object;\n",
    "ind.dataset_str.y => the one-hot labels of the labeled training instances as numpy.ndarray object;\n",
    "ind.dataset_str.ty => the one-hot labels of the test instances as numpy.ndarray object;\n",
    "ind.dataset_str.ally => the labels for instances in ind.dataset_str.allx as numpy.ndarray object;\n",
    "ind.dataset_str.graph => a dict in the format {index: [index_of_neighbor_nodes]} as collections.defaultdict\n",
    "    object;\n",
    "ind.dataset_str.test.index => the indices of test instances in graph, for the inductive setting as list object.\n",
    "\n",
    "All objects above must be saved using python pickle module.\n",
    "\n",
    ":param dataset_str: Dataset name\n",
    ":return: All data input files loaded (as well the training/test data).\n",
    "\"\"\"\n",
    "save_root = \"../data/ori_cora_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(features[idx_train], open(f\"{save_root}/ind.cora.x\", \"wb\" ) )\n",
    "pickle.dump(sp.vstack((features[:idx_test[0]], features[idx_test[-1]+1:])), open( (f\"{save_root}/ind.cora.allx\", \"wb\" ) )\n",
    "pickle.dump(features[idx_test], open( (f\"{save_root}/ind.cora.tx\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(labels[idx_train], open( (f\"{save_root}/ind.cora.y\", \"wb\" ) )\n",
    "pickle.dump(labels[idx_test], open( (f\"{save_root}/ind.cora.ty\", \"wb\" ) )\n",
    "pickle.dump(np.vstack((labels[:idx_test[0]],labels[idx_test[-1]+1:])), open( (f\"{save_root}/ind.cora.ally\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('(f\"{save_root}/ind.cora.test.index', 'w') as f:\n",
    "    for item in list(idx_test):\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ori_graph\n",
    "array_adj = np.argwhere(adj.toarray())\n",
    "ori_graph = defaultdict(list)\n",
    "for edge in array_adj:\n",
    "    ori_graph[edge[0]].append(edge[1])\n",
    "pickle.dump(ori_graph, open( \"(f\"{save_root}/ind.cora.graph\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of our format transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg.eigen.arpack import eigsh\n",
    "import sys\n",
    "\n",
    "def parse_index_file(filename):\n",
    "    \"\"\"Parse index file.\"\"\"\n",
    "    index = []\n",
    "    for line in open(filename):\n",
    "        index.append(int(line.strip()))\n",
    "    return index\n",
    "\n",
    "\n",
    "def sample_mask(idx, l):\n",
    "    \"\"\"Create mask.\"\"\"\n",
    "    mask = np.zeros(l)\n",
    "    mask[idx] = 1\n",
    "    return np.array(mask, dtype=np.bool)\n",
    "\n",
    "dataset_str='cora'\n",
    "names = ['x', 'y', 'tx', 'ty', 'allx', 'ally', 'graph']\n",
    "objects = []\n",
    "for i in range(len(names)):\n",
    "    with open(\"../data/ori_cora_data_nonormalize/ind.{}.{}\".format(dataset_str, names[i]), 'rb') as f:\n",
    "        if sys.version_info > (3, 0):\n",
    "            objects.append(pkl.load(f, encoding='latin1'))\n",
    "        else:\n",
    "            objects.append(pkl.load(f))\n",
    "\n",
    "x, y, tx, ty, allx, ally, graph = tuple(objects)\n",
    "test_idx_reorder = parse_index_file(\"../data/ori_cora_data_nonormalize/ind.{}.test.index\".format(dataset_str))\n",
    "test_idx_range = np.sort(test_idx_reorder)\n",
    "\n",
    "p_features = sp.vstack((allx[:test_idx_range[0]], tx, allx[test_idx_range[0]:])).tolil()\n",
    "p_features[test_idx_reorder, :] = features[test_idx_range, :]\n",
    "\n",
    "o_adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
    "\n",
    "o_labels = np.vstack((ally[:test_idx_range[0]], ty, ally[test_idx_range[0]:]))\n",
    "o_labels[test_idx_reorder, :] = labels[test_idx_range, :]\n",
    "\n",
    "idx_test = test_idx_range.tolist()\n",
    "idx_train = range(len(y))\n",
    "idx_val = range(len(y), len(y)+500)\n",
    "\n",
    "train_mask = sample_mask(idx_train, labels.shape[0])\n",
    "val_mask = sample_mask(idx_val, labels.shape[0])\n",
    "test_mask = sample_mask(idx_test, labels.shape[0])\n",
    "\n",
    "y_train = np.zeros(labels.shape)\n",
    "y_val = np.zeros(labels.shape)\n",
    "y_test = np.zeros(labels.shape)\n",
    "y_train[train_mask, :] = labels[train_mask, :]\n",
    "y_val[val_mask, :] = labels[val_mask, :]\n",
    "y_test[test_mask, :] = labels[test_mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p_features.nonzero()[0] == features.nonzero()[0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p_features.nonzero()[1] == features.nonzero()[1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2708x2708 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(adj!=o_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention, two loaded graph should be identical if their adj and feature are identical. Their label may (with high prpobability) not match with each other because of label match in\n",
    "```\n",
    "classes = set(idx_features_labels[:, -1])\n",
    "# classes.sort()\n",
    "# labels.nonzero()[1][:10]\n",
    "classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                enumerate(classes)}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Plantenoid Citation Data Format Transformation",
    "public": true
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
